# -*- coding: utf-8 -*-
"""
Post-Processing Script for MACE Molecular Dynamics Simulations

This script analyzes the output data from a MACE-driven MD simulation,
as generated by the accompanying 'run_mace_md.py' script. It computes
and visualizes key metrics for characterizing the simulated material,
including thermodynamic, structural, and transport properties.

The analyses performed are:
1.  Thermodynamic Stability: Plots temperature and energy evolution to
    confirm equilibration.
2.  Radial Distribution Function (RDF): Computes g(r) to characterize the
    short-range atomic structure.
3.  Mean Squared Displacement (MSD): Calculates MSD to analyze atomic mobility
    and computes the diffusion coefficient (D) via the Einstein relation.
4.  Velocity Autocorrelation Function (VACF): Provides insight into the
    vibrational dynamics (phonons).
5.  Thermal Conductivity (κ): Calculated using the Green-Kubo formula from
    the heat flux autocorrelation function (HFACF). A running integral is
    plotted to assess convergence.

This script is designed to produce publication-quality figures and adheres to
rigorous standards for scientific data analysis.

Author: Yi Cao
Date: August 14, 2025
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import correlate, correlation_lags
from scipy.integrate import simps
from scipy.stats import linregress
from ase.io import read
from ase.build import make_supercell
from ase.geometry import find_mic
from tqdm import tqdm

# Apply user-specific plotting style for publication-quality figures.
try:
    import jhu_colors
    # jhu_colors.set_style()
    get_jhu_color = jhu_colors.get_jhu_color
    # Define a color mapping for atom pairs
    COLOR_MAP = {
        'Cr-Te': get_jhu_color('Heritage Blue'),
        'Sb-Te': get_jhu_color('Spirit Blue'),
        'Te-Te': get_jhu_color('Homewood Green'),
        'Cr-Sb': get_jhu_color('Orange'),
        'Cr-Cr': get_jhu_color('Red'),
        'Sb-Sb': get_jhu_color('Purple'),
        'Total': get_jhu_color('Double Black'),
    }
except ImportError:
    print("Warning: 'jhu_colors' package not found. Using default matplotlib styles.")
    def get_jhu_color(x):
        return None # Fallback
    COLOR_MAP = {key: get_jhu_color(None) for key in ['Cr-Te', 'Sb-Te', 'Te-Te', 'Cr-Sb', 'Cr-Cr', 'Sb-Sb', 'Total']}


# --- Configuration ---
# Adjust these paths and parameters for your specific simulation.
BASE_PATH = './'
BASE_NAME = '2L_octo_Cr2_v2_relax'
suffix = '5x5x1_T600K'  # Suffix for the simulation box size and temperature
# whole name example: 2L_octo_Cr2_v2_relax_stress_5x5x1_T600K.csv

# The original unit cell file is required to reconstruct the simulation box.
UNIT_CELL_FILE = '../2L_octo_Cr2_v2_relax.extxyz'
SUPERCELL_MATRIX = np.diag([5, 5, 1])


# Directory to save the generated plots.
OUTPUT_DIR = f'./analysis_plots_{BASE_NAME}'

# --- Main Analysis Functions ---

def load_data(base_path, base_name):
    """Loads all necessary CSV files into a dictionary of pandas DataFrames."""
    print("--- Loading Data ---")
    file_paths = {
        'thermo': os.path.join(base_path, f'{base_name}_thermodynamics_{suffix}.csv'),
        'positions': os.path.join(base_path, f'{base_name}_positions_{suffix}.csv'),
        'velocities': os.path.join(base_path, f'{base_name}_velocities_{suffix}.csv'),
        'heat_flux': os.path.join(base_path, f'{base_name}_heat_flux_{suffix}.csv'),
    }
    dataframes = {}
    for key, path in file_paths.items():
        if os.path.exists(path):
            print(f"Loading {key} data from {path}...")
            dataframes[key] = pd.read_csv(path)
        else:
            print(f"Warning: {key} file not found at {path}. Some analyses may fail.")
            dataframes[key] = None
    return dataframes

def get_simulation_cell(unit_cell_file, supercell_matrix):
    """Reconstructs the supercell to get accurate cell dimensions and volume."""
    print("\n--- Reconstructing Simulation Cell ---")
    if not os.path.exists(unit_cell_file):
        raise FileNotFoundError(f"Unit cell file not found: {unit_cell_file}. "
                                "This is required for RDF and PBC calculations.")
    atoms = read(unit_cell_file)
    supercell = make_supercell(atoms, supercell_matrix)
    cell = supercell.get_cell()
    volume = supercell.get_volume()
    print(f"Cell vectors (Å):\n{cell}")
    print(f"Volume (Å³): {volume:.2f}")
    return cell, volume

def plot_thermodynamics(thermo_df, output_dir):
    """Plots temperature and energy evolution over time."""
    if thermo_df is None:
        return
    print("\n--- Plotting Thermodynamics ---")
    time_ps = thermo_df['time_fs'] / 1000.0
    fig, axes = plt.subplots(2, 1, figsize=(6, 8), sharex=True)

    # Plot 1: Energies
    ax = axes[0]
    ax.plot(time_ps, thermo_df['pot_energy_per_atom_eV'], label='Potential', color=get_jhu_color('Heritage Blue'))
    ax.plot(time_ps, thermo_df['kin_energy_per_atom_eV'], label='Kinetic', color=get_jhu_color('Spirit Blue'))
    total_energy = thermo_df['pot_energy_per_atom_eV'] + thermo_df['kin_energy_per_atom_eV']
    ax.plot(time_ps, total_energy, label='Total', color=get_jhu_color('Double Black'), linestyle='--')
    ax.set_ylabel('Energy (eV/atom)')
    ax.legend(loc='best')
    ax.grid(True, linestyle='--', alpha=0.6)
    ax.set_title('Energy Evolution')

    # Plot 2: Temperature
    ax = axes[1]
    ax.plot(time_ps, thermo_df['temperature_K'], color=get_jhu_color('Red'))
    avg_temp = thermo_df['temperature_K'].mean()
    ax.axhline(avg_temp, color=get_jhu_color('Double Black'), linestyle='--', label=f'Avg: {avg_temp:.1f} K')
    ax.set_ylabel('Temperature (K)')
    ax.set_xlabel('Time (ps)')
    ax.legend(loc='best')
    ax.grid(True, linestyle='--', alpha=0.6)
    ax.set_title('Temperature Fluctuation')

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'thermodynamics.pdf'), dpi=300)
    plt.close()
    print("Thermodynamics plot saved.")

def calculate_and_plot_rdf(positions_df, cell, output_dir, r_max=10.0, n_bins=200):
    """Calculates and plots the Radial Distribution Function (RDF)."""
    if positions_df is None:
        return
    print("\n--- Calculating Radial Distribution Function (RDF) ---")
    
    volume = np.linalg.det(cell)
    bins = np.linspace(0, r_max, n_bins + 1)
    bin_centers = (bins[:-1] + bins[1:]) / 2.0
    
    # Get unique atom types and create pairs
    atom_types = positions_df['atom_type'].unique()
    pairs = []
    for i in range(len(atom_types)):
        for j in range(i, len(atom_types)):
            pairs.append(tuple(sorted((atom_types[i], atom_types[j]))))
    pairs = sorted(list(set(pairs)))

    rdf_counts = {pair: np.zeros(n_bins) for pair in pairs}
    num_atoms_by_type = positions_df.groupby('atom_type')['atom_id'].nunique().to_dict()
    total_atoms = len(positions_df['atom_id'].unique())
    
    n_frames = 0
    grouped = positions_df.groupby('time_fs')
    
    for time, frame_df in tqdm(grouped, desc="Processing RDF frames"):
        n_frames += 1
        positions = frame_df[['x', 'y', 'z']].values
        types = frame_df['atom_type'].values
        
        # This is a simplified distance calculation. For full PBC across all pairs,
        # a more optimized approach might be needed for very large systems.
        # ASE's get_all_distances is efficient but requires an Atoms object per frame.
        for i in range(total_atoms):
            # find_mic computes distances with minimum image convention
            vectors, distances = find_mic(positions[i+1:] - positions[i], cell)
            
            for j_local, dist in enumerate(distances):
                j_global = i + 1 + j_local
                if dist < r_max:
                    pair = tuple(sorted((types[i], types[j_global])))
                    bin_idx = np.searchsorted(bins, dist) - 1
                    if bin_idx >= 0:
                        rdf_counts[pair][bin_idx] += 2 # Count each pair once for i-j and j-i

    # Normalization
    rdf_final = {}
    for pair, counts in rdf_counts.items():
        type1, type2 = pair
        N1 = num_atoms_by_type[type1]
        N2 = num_atoms_by_type[type2]
        
        norm_factor = (N1 * (N2 - (1 if type1 == type2 else 0))) / volume
        
        # Volume of spherical shells
        shell_volumes = 4.0 * np.pi * bin_centers**2 * (r_max / n_bins)
        
        # Avoid division by zero for the first bin
        shell_volumes[0] = 4./3. * np.pi * bins[1]**3
        
        g_r = counts / (n_frames * norm_factor * shell_volumes)
        rdf_final[pair] = g_r

    # Plotting
    plt.figure(figsize=(8, 6))
    for pair_name, g_r in rdf_final.items():
        label = f'{pair_name[0]}-{pair_name[1]}'
        plt.plot(bin_centers, g_r, label=label, color=COLOR_MAP.get(label, get_jhu_color('Double Black')))
    
    plt.title('Radial Distribution Function (RDF)')
    plt.xlabel('Distance, r (Å)')
    plt.ylabel('g(r)')
    plt.axhline(1.0, color='gray', linestyle='--')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.xlim(0, r_max)
    plt.ylim(bottom=0)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'rdf.pdf'), dpi=300)
    plt.close()
    print("RDF plot saved.")


def calculate_and_plot_msd(positions_df, output_dir, dt_fs, fit_start_ps=5.0):
    """Calculates MSD, plots it, and computes the diffusion coefficient."""
    if positions_df is None:
        return
    print("\n--- Calculating Mean Squared Displacement (MSD) ---")
    
    # Calculate squared displacement for each atom at each time step
    positions_df['d_sq'] = positions_df['dx_from_init']**2 + positions_df['dy_from_init']**2 + positions_df['dz_from_init']**2
    
    # Average over all atoms to get MSD at each time step
    msd_df = positions_df.groupby('time_fs')['d_sq'].mean().reset_index()
    msd_df['time_ps'] = msd_df['time_fs'] / 1000.0
    
    # Plotting
    plt.figure(figsize=(6, 4))
    plt.plot(msd_df['time_ps'], msd_df['d_sq'], color=get_jhu_color('Heritage Blue'), label='MSD')
    
    # --- Diffusion Coefficient Calculation ---
    # Fit the linear region of the MSD curve (t -> infinity)
    fit_df = msd_df[msd_df['time_ps'] >= fit_start_ps]
    if len(fit_df) > 2:
        # Time needs to be in seconds for standard units
        time_s = fit_df['time_fs'] * 1e-15
        # MSD needs to be in m^2
        msd_m2 = fit_df['d_sq'] * 1e-20
        
        slope, intercept, r_value, _, _ = linregress(time_s, msd_m2)
        
        # Einstein relation: MSD = 6Dt for 3D diffusion
        # D in m^2/s
        diffusion_coeff_m2_s = slope / 6.0
        # Convert to cm^2/s for more common representation
        diffusion_coeff_cm2_s = diffusion_coeff_m2_s * 1e4
        
        print(f"Diffusion Coefficient (D) from MSD slope: {diffusion_coeff_cm2_s:.4e} cm²/s")
        
        # Plot the fit line
        fit_line_m2 = slope * time_s + intercept
        fit_line_A2 = fit_line_m2 * 1e20 # convert back to Å^2 for plotting
        plt.plot(fit_df['time_ps'], fit_line_A2, color=get_jhu_color('Red'), linestyle='--', 
                 label=f'Linear Fit (D={diffusion_coeff_cm2_s:.2e} cm²/s)')

    plt.title('Mean Squared Displacement (MSD)')
    plt.xlabel('Time (ps)')
    plt.ylabel(r'MSD (Å²)')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'msd_diffusion.pdf'), dpi=300)
    plt.close()
    print("MSD and Diffusion plot saved.")


def calculate_autocorr_fft(df, columns):
    """Calculates the autocorrelation of vector components using FFT."""
    # Detrend the data (subtract mean)
    data = df[columns].values
    data_detrended = data - data.mean(axis=0)
    
    # Perform FFT
    fft_data = np.fft.fft(data_detrended, n=2*len(data_detrended)-1, axis=0)
    
    # Calculate power spectral density
    psd = np.abs(fft_data)**2
    
    # Inverse FFT gives the autocorrelation
    autocorr = np.fft.ifft(psd, axis=0).real
    
    # Normalize
    autocorr /= autocorr[0]
    
    return autocorr[:len(data)]


def plot_vacf(velocities_df, output_dir, dt_fs):
    """Calculates and plots the Velocity Autocorrelation Function (VACF)."""
    if velocities_df is None:
        return
    print("\n--- Calculating Velocity Autocorrelation Function (VACF) ---")
    
    # Average VACF over all atoms
    vacf_sum = None
    atom_ids = velocities_df['atom_id'].unique()
    
    for atom_id in tqdm(atom_ids, desc="Processing VACF per atom"):
        atom_vel_df = velocities_df[velocities_df['atom_id'] == atom_id]
        if vacf_sum is None:
            vacf_sum = calculate_autocorr_fft(atom_vel_df, ['vx', 'vy', 'vz'])
        else:
            vacf_sum += calculate_autocorr_fft(atom_vel_df, ['vx', 'vy', 'vz'])
            
    vacf_avg = vacf_sum / len(atom_ids)
    
    time_fs = velocities_df['time_fs'].unique()
    time_ps = time_fs / 1000.0
    
    # Plotting
    plt.figure(figsize=(6, 4))
    plt.plot(time_ps, vacf_avg, color=get_jhu_color('Heritage Blue'))
    plt.title('Velocity Autocorrelation Function (VACF)')
    plt.xlabel('Time (ps)')
    plt.ylabel('Normalized VACF')
    plt.axhline(0, color='gray', linestyle='--')
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.xlim(0, time_ps[-1] / 2) # Show first half of correlation time
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'vacf.pdf'), dpi=300)
    plt.close()
    print("VACF plot saved.")


def plot_hfacf_and_conductivity(heat_flux_df, thermo_df, volume_A3, output_dir, dt_fs):
    """Calculates thermal conductivity via Green-Kubo from the HFACF."""
    if heat_flux_df is None or thermo_df is None:
        return
    print("\n--- Calculating Thermal Conductivity (Green-Kubo) ---")
    
    # --- Calculate HFACF ---
    # Note: The heat flux calculation in the simulation script is an approximation.
    # The resulting thermal conductivity is therefore also an approximation.
    hfacf_x = calculate_autocorr_fft(heat_flux_df, ['Jx'])
    hfacf_y = calculate_autocorr_fft(heat_flux_df, ['Jy'])
    hfacf_z = calculate_autocorr_fft(heat_flux_df, ['Jz'])
    
    # Average over three directions for isotropic conductivity
    hfacf_avg = (hfacf_x + hfacf_y + hfacf_z) / 3.0
    
    time_fs = heat_flux_df['time_fs'].unique()
    time_ps = time_fs / 1000.0
    
    # --- Plot HFACF ---
    fig, axes = plt.subplots(2, 1, figsize=(6, 8), sharex=True)
    ax = axes[0]
    ax.plot(time_ps, hfacf_avg, color=get_jhu_color('Heritage Blue'))
    ax.set_title('Heat Flux Autocorrelation Function (HFACF)')
    ax.set_ylabel('Normalized HFACF')
    ax.axhline(0, color='gray', linestyle='--')
    ax.grid(True, linestyle='--', alpha=0.6)
    ax.set_xlim(0, 5) # Correlation typically decays quickly

    # --- Integrate HFACF to get Kappa ---
    # Green-Kubo Formula: κ = (V / (3 * kB * T^2)) * integral(HFACF * <J^2>) dt
    
    # Constants
    kB_eV_K = 8.617333262145e-5  # Boltzmann constant in eV/K
    
    # System properties
    avg_temp_K = thermo_df['temperature_K'].mean()
    
    # Un-normalize the HFACF
    j_sq_avg = (heat_flux_df['Jx']**2 + heat_flux_df['Jy']**2 + heat_flux_df['Jz']**2).mean()
    hfacf_unnormalized = hfacf_avg * j_sq_avg
    
    # Prefactor for Green-Kubo formula (in MD units)
    # Units: V[Å³] / (kB[eV/K] * T[K]²)
    prefactor = volume_A3 / (kB_eV_K * avg_temp_K**2)
    
    # Integrate using Simpson's rule for better accuracy
    # dt is in fs
    integral_values = np.array([simps(hfacf_unnormalized[:i], dx=dt_fs) for i in range(1, len(time_fs) + 1)])
    
    # Isotropic thermal conductivity (average of diagonal components)
    kappa_iso = (prefactor / 3.0) * integral_values
    
    # Conversion factor from MD units [eV/(fs·Å)] to standard [W/(m·K)]
    # 1 eV = 1.60218e-19 J
    # 1 fs = 1e-15 s
    # 1 Å = 1e-10 m
    # Factor = (1.60218e-19) / (1e-15 * 1e-10) = 1.60218e6
    eV_fsA_to_W_mK = 1.60218e6
    
    kappa_iso_W_mK = kappa_iso * eV_fsA_to_W_mK
    
    final_kappa = kappa_iso_W_mK[-1]
    print(f"Converged Thermal Conductivity (κ): {final_kappa:.3f} W/(m·K)")
    print(f"(Note: This value is based on an approximate heat flux calculation.)")

    # Plot running integral of kappa
    ax = axes[1]
    ax.plot(time_ps, kappa_iso_W_mK, color=get_jhu_color('Red'))
    ax.set_title('Thermal Conductivity (Running Integral)')
    ax.set_xlabel('Integration Time (ps)')
    ax.set_ylabel('κ (W/m·K)')
    ax.axhline(final_kappa, color='gray', linestyle='--', label=f'Final κ = {final_kappa:.2f}')
    ax.grid(True, linestyle='--', alpha=0.6)
    ax.legend()
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'hfacf_conductivity.pdf'), dpi=300)
    plt.close()
    print("HFACF and Conductivity plot saved.")


def main():
    """Main execution function."""
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
        print(f"Created output directory: {OUTPUT_DIR}")

    # Load data from CSV files
    data = load_data(BASE_PATH, BASE_NAME)
    if not data:
        print("No data loaded. Exiting.")
        return
        
    # Reconstruct cell to get dimensions for PBC
    try:
        cell, volume = get_simulation_cell(UNIT_CELL_FILE, SUPERCELL_MATRIX)
    except FileNotFoundError as e:
        print(f"Error: {e}")
        print("Cannot proceed with RDF calculation without the unit cell file.")
        cell, volume = None, data['thermo']['volume_A3'].mean() if data['thermo'] is not None else 0

    # Get time step from data
    if data['thermo'] is not None:
        dt_fs = data['thermo']['time_fs'].diff().mean()
        print(f"\nDetected time step (dt): {dt_fs:.2f} fs")
    else:
        print("Cannot determine time step. Assuming 1 fs.")
        dt_fs = 1.0

    # --- Run all analysis and plotting functions ---
    plot_thermodynamics(data['thermo'], OUTPUT_DIR)
    
    if cell is not None:
        calculate_and_plot_rdf(data['positions'], cell, OUTPUT_DIR)
    
    calculate_and_plot_msd(data['positions'], OUTPUT_DIR, dt_fs, fit_start_ps=5.0)
    
    plot_vacf(data['velocities'], OUTPUT_DIR, dt_fs)
    
    plot_hfacf_and_conductivity(data['heat_flux'], data['thermo'], volume, OUTPUT_DIR, dt_fs)
    
    print("\n--- Analysis Complete ---")
    print(f"All plots saved in: {OUTPUT_DIR}")


if __name__ == "__main__":
    main()
